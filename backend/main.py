"""
AIè´­ç‰©åŠ©æ‰‹åç«¯æœåŠ¡
åŸºäº FastAPI + é€šä¹‰åƒé—® API
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
import os
from openai import OpenAI
from dotenv import load_dotenv
import json
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="AIè´­ç‰©åŠ©æ‰‹ API",
    description="ç¤¼ç‰©æ¨èèŠå¤©æœºå™¨äººåç«¯æœåŠ¡",
    version="1.0.0"
)

# é…ç½® CORS - å…è®¸å°ç¨‹åºè°ƒç”¨
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒéœ€è¦é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–é€šä¹‰åƒé—®å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# æ•°æ®æ¨¡å‹
class Message(BaseModel):
    """å•æ¡æ¶ˆæ¯"""
    role: str  # 'user' æˆ– 'assistant'
    content: str

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str  # ç”¨æˆ·å½“å‰è¾“å…¥
    history: Optional[List[Message]] = []  # å†å²å¯¹è¯

class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    response: str  # AIå›å¤
    suggestions: Optional[List[str]] = []  # å»ºè®®çš„å¿«æ·å›å¤


# ç³»ç»Ÿæç¤ºè¯ - å®šä¹‰AIåŠ©æ‰‹çš„è§’è‰²
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¼ç‰©æ¨èé¡¾é—®ï¼Œåå­—å«"å“ç­”ç­”"ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡å¯¹è¯å¸®åŠ©ç”¨æˆ·æ‰¾åˆ°æœ€åˆé€‚çš„ç¤¼ç‰©ã€‚

ä½ éœ€è¦ï¼š
1. å‹å¥½ã€çƒ­æƒ…åœ°ä¸ç”¨æˆ·äº¤æµ
2. é€šè¿‡æé—®æ”¶é›†ä¿¡æ¯ï¼šé€ç¤¼å¯¹è±¡ã€åœºåˆã€é¢„ç®—ã€å¯¹æ–¹å–œå¥½ç­‰
3. æ ¹æ®æ”¶é›†çš„ä¿¡æ¯ï¼Œæ¨èåˆé€‚çš„ç¤¼ç‰©
4. å›ç­”è¦ç®€æ´ã€æœ‰æ¡ç†ï¼Œé€‚å½“ä½¿ç”¨emojiè®©å¯¹è¯æ›´ç”ŸåŠ¨
5. å¦‚æœç”¨æˆ·æä¾›çš„ä¿¡æ¯ä¸å¤Ÿï¼Œä¸»åŠ¨è¿½é—®å…³é”®ä¿¡æ¯

ç¤¼ç‰©æ¨èèŒƒå›´åŒ…æ‹¬ï¼š
- æ•°ç äº§å“ï¼šè€³æœºã€æ‰‹è¡¨ã€é”®ç›˜ç­‰
- ç¾å¦†æŠ¤è‚¤ï¼šå£çº¢ã€é¦™æ°´ã€æŠ¤è‚¤å¥—è£…
- æ—¶å°šé…é¥°ï¼šåŒ…åŒ…ã€é¦–é¥°ã€å›´å·¾
- è¿åŠ¨è£…å¤‡ï¼šçƒé‹ã€è¿åŠ¨åŒ…ã€å¥èº«å™¨æ
- åˆ›æ„ç¤¼ç‰©ï¼šå®šåˆ¶ç¤¼ç‰©ã€æ‰‹å·¥åˆ¶å“ã€çºªå¿µå“

è¯·ä¿æŒå›å¤ç®€æ´ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼Œä¸è¦è¿‡äºå†—é•¿ã€‚"""


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "ok",
        "message": "AIè´­ç‰©åŠ©æ‰‹åç«¯æœåŠ¡è¿è¡Œä¸­",
        "version": "1.0.0"
    }


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    AIå¯¹è¯æ¥å£ï¼ˆéæµå¼ï¼‰

    æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å’Œå†å²å¯¹è¯ï¼Œè¿”å›AIå›å¤å’Œå»ºè®®å›å¤
    """
    try:
        # æ„å»ºå¯¹è¯å†å²
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]

        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘10è½®å¯¹è¯ï¼‰
        if request.history:
            recent_history = request.history[-20:]  # ä¿ç•™æœ€è¿‘20æ¡æ¶ˆæ¯ï¼ˆ10è½®å¯¹è¯ï¼‰
            for msg in recent_history:
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": request.message
        })

        # è°ƒç”¨é€šä¹‰åƒé—® API
        completion = client.chat.completions.create(
            model="qwen-max",  # qwen-max: æœ€å¼ºæ¨ç†èƒ½åŠ›
            messages=messages,
            temperature=0.8,  # æ§åˆ¶å›å¤çš„åˆ›é€ æ€§ï¼Œ0-2ä¹‹é—´
            max_tokens=500,   # é™åˆ¶å›å¤é•¿åº¦
        )

        # æå–AIå›å¤
        ai_response = completion.choices[0].message.content

        # ç”Ÿæˆå»ºè®®å›å¤ï¼ˆæ ¹æ®å¯¹è¯å†…å®¹æ™ºèƒ½ç”Ÿæˆï¼‰
        suggestions = generate_suggestions(request.message, ai_response)

        return ChatResponse(
            response=ai_response,
            suggestions=suggestions
        )

    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AIæœåŠ¡å¼‚å¸¸: {str(e)}")


@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    AIå¯¹è¯æ¥å£ï¼ˆæµå¼è¾“å‡ºï¼‰

    ä½¿ç”¨SSEæ ¼å¼é€å­—è¿”å›AIå›å¤ï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
    """
    async def generate():
        try:
            # æ„å»ºå¯¹è¯å†å²
            messages = [{"role": "system", "content": SYSTEM_PROMPT}]

            # æ·»åŠ å†å²æ¶ˆæ¯
            if request.history:
                recent_history = request.history[-20:]
                for msg in recent_history:
                    messages.append({
                        "role": msg.role,
                        "content": msg.content
                    })

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": request.message
            })

            # è°ƒç”¨é€šä¹‰åƒé—® APIï¼ˆæµå¼ï¼‰
            stream = client.chat.completions.create(
                model="qwen-max",  # qwen-max: æœ€å¼ºæ¨ç†èƒ½åŠ›
                messages=messages,
                temperature=0.8,
                max_tokens=500,
                stream=True,  # å¼€å¯æµå¼è¾“å‡º
            )

            full_response = ""

            # é€å—è¿”å›æ•°æ®
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content

                    # æŒ‰ç…§SSEæ ¼å¼è¿”å›æ•°æ®
                    data = {
                        "type": "content",
                        "content": content,
                        "full_text": full_response
                    }
                    yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

                    # æ·»åŠ å°å»¶è¿Ÿï¼Œè®©å‰ç«¯æœ‰æ—¶é—´å¤„ç†
                    await asyncio.sleep(0.01)

            # å‘é€å®Œæˆæ ‡è®°å’Œå»ºè®®å›å¤
            suggestions = generate_suggestions(request.message, full_response)
            final_data = {
                "type": "done",
                "full_text": full_response,
                "suggestions": suggestions
            }
            yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"

        except Exception as e:
            error_data = {
                "type": "error",
                "message": f"AIæœåŠ¡å¼‚å¸¸: {str(e)}"
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨nginxç¼“å†²
        }
    )


def generate_suggestions(user_message: str, ai_response: str) -> List[str]:
    """
    æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆå»ºè®®çš„å¿«æ·å›å¤
    """
    suggestions = []

    # åŸºäºå…³é”®è¯ç”Ÿæˆå»ºè®®
    msg_lower = user_message.lower()

    if "æ¨è" in user_message or "å»ºè®®" in user_message:
        suggestions = ["çœ‹çœ‹å…·ä½“å•†å“", "é¢„ç®—å¯ä»¥è°ƒæ•´", "è¿˜æœ‰å…¶ä»–é€‰æ‹©å—"]
    elif "é¢„ç®—" in user_message or "ä»·æ ¼" in user_message:
        suggestions = ["è¿™ä¸ªä»·ä½ä¸é”™", "èƒ½ä¾¿å®œç‚¹å—", "æˆ‘æƒ³çœ‹çœ‹æ¨è"]
    elif "ç”·æœ‹å‹" in user_message or "å¥³æœ‹å‹" in user_message:
        suggestions = ["å‘Šè¯‰ä½ æ›´å¤šå–œå¥½", "çœ‹çœ‹æ¨èå§", "é¢„ç®—500å·¦å³"]
    elif "ç”Ÿæ—¥" in user_message or "çºªå¿µæ—¥" in user_message:
        suggestions = ["æƒ³è¦æƒŠå–œæ„Ÿ", "å®ç”¨æ€§ä¸ºä¸»", "çœ‹çœ‹æ¨è"]
    else:
        # é»˜è®¤å»ºè®®
        suggestions = ["æˆ‘æƒ³çœ‹çœ‹æ¨è", "è¿˜æœ‰å…¶ä»–çš„å—", "è¿™äº›ä¸é”™"]

    return suggestions


@app.get("/health")
async def health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    api_key_status = "å·²é…ç½®" if os.getenv("DASHSCOPE_API_KEY") else "æœªé…ç½®"

    return {
        "status": "healthy",
        "api_key": api_key_status,
        "model": "qwen-plus",
        "version": "1.0.0"
    }


if __name__ == "__main__":
    import uvicorn

    # å¯åŠ¨æœåŠ¡
    print("ğŸš€ å¯åŠ¨ AIè´­ç‰©åŠ©æ‰‹åç«¯æœåŠ¡...")
    print("ğŸ“ æœåŠ¡åœ°å€: http://localhost:8000")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ”‘ API Key çŠ¶æ€:", "å·²é…ç½®" if os.getenv("DASHSCOPE_API_KEY") else "æœªé…ç½®")

    uvicorn.run(
        "main:app",  # ä½¿ç”¨å­—ç¬¦ä¸²å¯¼å…¥ä»¥æ”¯æŒ reload
        host="0.0.0.0",
        port=8000,
        reload=True  # å¼€å‘æ¨¡å¼ï¼šä»£ç ä¿®æ”¹è‡ªåŠ¨é‡å¯
    )
